{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import spacy # use <!pip install spacy> and <!python -m spacy download en> if you dont have spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#select the path where you want to save model prameters\n",
    "\n",
    "PATH = '/home/sanala/Juputer try/HSD/model-parameters/bi-lstm-hasoc.pt'\n",
    "\n",
    "\n",
    "#Select which data you want to work with \n",
    "#data path\n",
    "DataPath= '/home/sanala/Juputer try/HSD'   #change it to your path\n",
    "#data\n",
    "train_data='has21_traindata.csv'           #<has20_traindata.csv> or <has21_traindata.csv> or <has19-20-21_conmined_train.csv>\n",
    "valid_data='has21_devdata.csv'             #<has21_devdata.csv> or <has21_devdata.csv> or <has19-20-21_conmined_valid.csv>\n",
    "test_data= 'hasoc21_testwithlabels.csv'            #<has21_testdata.csv> or <has21_testdatawithlabels.csv> <has21_testdata.csv>\n",
    "\n",
    "\n",
    "    \n",
    "def hasoc_combined_data():\n",
    "    data1a = pd.read_csv('has19_traindata.csv')\n",
    "    data2b = pd.read_csv('has19_devdata.csv')\n",
    "    data1aa = pd.read_csv('has20_traindata.csv')\n",
    "    data2bb = pd.read_csv('has20_devdata.csv')\n",
    "    data1aaa = pd.read_csv('has21_traindata.csv')\n",
    "    data2bbb = pd.read_csv('has21_devdata.csv')\n",
    "    \n",
    "    train_data, valid_data = pd.concat([data1a, data1aa, data1aaa]), pd.concat([data2b, data2bb, data2bbb])\n",
    "    test_data='hasoc21_testwithlabels.csv'\n",
    "    #if datayear == '2020':\n",
    "            #print('Using Hasoc combined data for Hasoc 2020 test data... ')\n",
    "            #testdata = pd.read_csv(args.has20_testdata)\n",
    "    #else:\n",
    "            #print('Using Hasoc combined data for Hasoc 2021 test data... ')\n",
    "    train_data.to_csv('/home/sanala/Juputer try/HSD/has19-20-21_conmined_train.csv')\n",
    "    valid_data.to_csv('/home/sanala/Juputer try/HSD/has19-20-21_conmined_valid.csv')\n",
    "    \n",
    "\n",
    "#set to True if you want to work with hasoc_combined 19_20_21\n",
    "hasoc_combined=False\n",
    "\n",
    "if hasoc_combined:\n",
    "    hasoc_combined_data()\n",
    "    train_data='has19-20-21_conmined_train.csv'           #<has21_traindata.csv> or <has_combined_traindata.csv>\n",
    "    valid_data='has19-20-21_conmined_valid.csv'             #<has21_devdata.csv> or <has21_devdata.csv>\n",
    "    test_data= 'has21_testdatawithlabels.csv'\n",
    "    \n",
    "\n",
    "#pre-preocessing \n",
    "def text_clean(text):\n",
    "    text = re.sub(r'[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', text)                  # remove emails                    \n",
    "    text = re.sub(r'((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', text)# remove IP address\n",
    "    text = re.sub(r'http\\S+', '', text)                                          # remove URLs\n",
    "    text = re.sub(r'www\\S+ ', '', text)                                          # remove URLs\n",
    "    text = re.sub(r'[^\\w\\s#@/:%.,_-]', '', text, flags=re.UNICODE)               # remove emojis+\n",
    "    text = re.sub(r'[#,@,&,<,>,\\,/,-]', '', text)\n",
    "    #text = text.replace('[^\\w\\s#@/:%.,_-]', '', flags=re.UNICODE)\n",
    "    text = text.replace('[','')\n",
    "    text = text.replace(']','')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(' {2,}', ' ')                                            # remove 2 or more spaces\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d', '', text)                                              # remove numbers\n",
    "\n",
    "    return text\n",
    "\n",
    "# define model\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, \n",
    "                 output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
    "                           bidirectional = bidirectional, dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "       \n",
    "        return self.fc(hidden.squeeze(0))\n",
    "    \n",
    "#define function to plot training  loss vs validation loss to check  overfitting     \n",
    "def plotLosses(train_losses,val_losses):\n",
    "    plt.plot(train_losses,label='Training Loss')  \n",
    "    plt.plot(val_losses,label='Validation Loss')  \n",
    "    plt.legend() \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "#function to return  scors   \n",
    "def f1_score_func(preds, labels):\n",
    "    return f1_score(labels, preds, average=None), f1_score(labels, preds, average=\"weighted\"), f1_score(labels, preds, average=\"micro\")\n",
    "\n",
    "#training function \n",
    "def train(model, train_iterator, optimizer, criterion):\n",
    "    print ('start training' )   \n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = criterion(predictions, batch.task_1)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc += acc.item()\n",
    "             \n",
    "    return train_epoch_loss / len(train_iterator), train_epoch_acc / len(train_iterator)\n",
    "\n",
    "#Evaluation  function\n",
    "def evaluation(model,valid_iterator):\n",
    "    print('Thin is the validation result')\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_acc = 0\n",
    "    predictions_tst = []\n",
    "    true_vals=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for batch in valid_iterator:\n",
    "\n",
    "          predictions = model(batch.text).squeeze(1)\n",
    "          for a in predictions:            # pick each element - no list comprehension\n",
    "            predictions_tst.append(torch.round(torch.sigmoid(a)))\n",
    "          for a in batch.task_1: \n",
    "            true_vals.append(a)\n",
    "\n",
    "          loss = criterion(predictions, batch.task_1)\n",
    "\n",
    "          rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "          correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "          acc = correct.sum()/len(correct)\n",
    "\n",
    "          valid_epoch_loss += loss.item()\n",
    "          valid_epoch_acc += acc.item()\n",
    "\n",
    "    predictions_tst = torch.stack(predictions_tst)\n",
    "    true_vals = torch.stack(true_vals)\n",
    "    #valid_loss = valid_epoch_loss / len(valid_iterator)\n",
    "    #valid_acc = valid_epoch_acc / len(valid_iterator) \n",
    "       \n",
    "    return valid_epoch_loss / len(valid_iterator), valid_epoch_acc / len(valid_iterator ),predictions_tst,true_vals    \n",
    "\n",
    "#test function\n",
    "\n",
    "def test(model, test_iterator,path):\n",
    "  print ('this the testing result' )   \n",
    "\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.load_state_dict(torch.load(path))\n",
    "\n",
    "  model.eval()\n",
    "  predictions_tst = []\n",
    "  true_vals=[]\n",
    "  IDs=[]\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "      for batch in test_iterator:\n",
    "\n",
    "          predictions = model(batch.text).squeeze(1)\n",
    "          for a in predictions:            # pick each element - no list comprehension\n",
    "            predictions_tst.append(torch.round(torch.sigmoid(a)))\n",
    "          for a in batch.task_1: \n",
    "            true_vals.append(a)\n",
    "          for a in batch._id: \n",
    "            IDs.append(a)#better if it was a dictionary (id:label)\n",
    "          loss = criterion(predictions, batch.task_1)\n",
    "          rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "          correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "          acc = correct.sum()/len(correct)\n",
    "\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_acc += acc.item()\n",
    "\n",
    "  predictions_tst = torch.stack(predictions_tst)\n",
    "  true_vals = torch.stack(true_vals)\n",
    " \n",
    "  test_loss = epoch_loss / len(test_iterator)\n",
    "  test_acc = epoch_acc / len(test_iterator)\n",
    "  return test_loss , test_acc,predictions_tst,true_vals,IDs\n",
    "\n",
    "#function to test user input\n",
    "def predict_class(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start pre-processin\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s): \n",
    "    return [w.text.lower() for w in nlp(text_clean(s))]\n",
    "TEXT = torchtext.legacy.data.Field(tokenize = tokenizer)\n",
    "\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)\n",
    "ID = torchtext.legacy.data.RawField()\n",
    "\n",
    "datafields = [('_id', ID) ,('text', TEXT),('task_1', LABEL) ,('task_2', None)]\n",
    "\n",
    "#read data\n",
    "#change the path \n",
    "trn,vld, tst = torchtext.legacy.data.TabularDataset.splits(path =DataPath, \n",
    "                                                train = train_data,\n",
    "                                                validation=valid_data,\n",
    "                                                test = test_data,    \n",
    "                                                format = 'csv',\n",
    "                                                skip_header = True,\n",
    "                                                fields = datafields)\n",
    "#check data\n",
    "#print(f'Number of training examples: {len(trn)}')\n",
    "#print(f'Number of validation examples: {len(vld)}')\n",
    "#print(f'Number of testing examples: {len(tst)}')\n",
    "\n",
    "#vars(trn.examples[0\n",
    "#vars(tst.examples[50])\n",
    "\n",
    "TEXT.build_vocab(trn, max_size=25000,\n",
    "                 vectors=\"glove.6B.100d\",## #pretrained vectors are ['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d']\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)\n",
    "#print(LABEL.vocab.stoi)\n",
    "train_iterator,valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "                                (trn,vld, tst),\n",
    "                                batch_size = 50,\n",
    "                                sort_key=lambda x: len(x.text),\n",
    "                                sort_within_batch=False,\n",
    "                                device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 20\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "model = RNN(input_dim, \n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            output_dim, \n",
    "            n_layers, \n",
    "            bidirectional, \n",
    "            dropout)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "#print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
    "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model=model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "#print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 01 | Train Loss: 0.658 | Train Acc: 62.13% | Valid Loss: 0.637 | Valid Acc: 65.39 | F1: [0.78740157 0.        ], weighted F1: 0.5112997238981491, micro F1: 0.6493506493506493%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      1.00      0.79       250\n",
      "         1.0       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.65       385\n",
      "   macro avg       0.32      0.50      0.39       385\n",
      "weighted avg       0.42      0.65      0.51       385\n",
      "\n",
      "Validation loss decreased (inf --> 0.636609).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 02 | Train Loss: 0.643 | Train Acc: 64.86% | Valid Loss: 0.624 | Valid Acc: 66.75 | F1: [0.7826087  0.24418605], weighted F1: 0.5938111433561384, micro F1: 0.6623376623376623%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.94      0.78       250\n",
      "         1.0       0.57      0.16      0.24       135\n",
      "\n",
      "    accuracy                           0.66       385\n",
      "   macro avg       0.62      0.55      0.51       385\n",
      "weighted avg       0.64      0.66      0.59       385\n",
      "\n",
      "Validation loss decreased (0.636609 --> 0.624090).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 03 | Train Loss: 0.614 | Train Acc: 66.60% | Valid Loss: 0.637 | Valid Acc: 61.54 | F1: [0.66361556 0.55855856], weighted F1: 0.6267773910794505, micro F1: 0.6181818181818182%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.58      0.66       250\n",
      "         1.0       0.47      0.69      0.56       135\n",
      "\n",
      "    accuracy                           0.62       385\n",
      "   macro avg       0.62      0.63      0.61       385\n",
      "weighted avg       0.67      0.62      0.63       385\n",
      "\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 04 | Train Loss: 0.571 | Train Acc: 70.31% | Valid Loss: 0.531 | Valid Acc: 74.00 | F1: [0.80464217 0.60079051], weighted F1: 0.7331617167627594, micro F1: 0.7376623376623377%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.83      0.80       250\n",
      "         1.0       0.64      0.56      0.60       135\n",
      "\n",
      "    accuracy                           0.74       385\n",
      "   macro avg       0.71      0.70      0.70       385\n",
      "weighted avg       0.73      0.74      0.73       385\n",
      "\n",
      "Validation loss decreased (0.624090 --> 0.531421).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 05 | Train Loss: 0.523 | Train Acc: 75.62% | Valid Loss: 0.520 | Valid Acc: 75.32 | F1: [0.812749   0.64925373], weighted F1: 0.7554194927983356, micro F1: 0.7558441558441559%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.82      0.81       250\n",
      "         1.0       0.65      0.64      0.65       135\n",
      "\n",
      "    accuracy                           0.76       385\n",
      "   macro avg       0.73      0.73      0.73       385\n",
      "weighted avg       0.76      0.76      0.76       385\n",
      "\n",
      "Validation loss decreased (0.531421 --> 0.520488).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 06 | Train Loss: 0.478 | Train Acc: 78.24% | Valid Loss: 0.506 | Valid Acc: 76.32 | F1: [0.82213439 0.65909091], weighted F1: 0.7649632975719932, micro F1: 0.7662337662337663%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.83      0.82       250\n",
      "         1.0       0.67      0.64      0.66       135\n",
      "\n",
      "    accuracy                           0.77       385\n",
      "   macro avg       0.74      0.74      0.74       385\n",
      "weighted avg       0.76      0.77      0.76       385\n",
      "\n",
      "Validation loss decreased (0.520488 --> 0.505765).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 07 | Train Loss: 0.446 | Train Acc: 80.24% | Valid Loss: 0.495 | Valid Acc: 79.29 | F1: [0.84836852 0.68273092], weighted F1: 0.7902878057585179, micro F1: 0.7948051948051948%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.88      0.85       250\n",
      "         1.0       0.75      0.63      0.68       135\n",
      "\n",
      "    accuracy                           0.79       385\n",
      "   macro avg       0.78      0.76      0.77       385\n",
      "weighted avg       0.79      0.79      0.79       385\n",
      "\n",
      "Validation loss decreased (0.505765 --> 0.494973).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 08 | Train Loss: 0.412 | Train Acc: 81.85% | Valid Loss: 0.504 | Valid Acc: 79.04 | F1: [0.84962406 0.66386555], weighted F1: 0.784487957862571, micro F1: 0.7922077922077922%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.90      0.85       250\n",
      "         1.0       0.77      0.59      0.66       135\n",
      "\n",
      "    accuracy                           0.79       385\n",
      "   macro avg       0.78      0.74      0.76       385\n",
      "weighted avg       0.79      0.79      0.78       385\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this the testing result\n",
      "Test Loss: 0.505 | Test Acc: 78.69 F1: [0.83939039 0.67990654], weighted F1: 0.7792571339072921, micro F1: 0.7861046057767369 % \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.90      0.84       798\n",
      "         1.0       0.78      0.60      0.68       483\n",
      "\n",
      "    accuracy                           0.79      1281\n",
      "   macro avg       0.78      0.75      0.76      1281\n",
      "weighted avg       0.79      0.79      0.78      1281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 8\n",
    "valid_loss_min = np.Inf \n",
    "val_losses=[]\n",
    "train_losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc,predictions,true_vals = evaluation(model, valid_iterator)\n",
    "    val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions.detach().cpu().numpy()\n",
    ", true_vals.detach().cpu().numpy())\n",
    "    #val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions, true_vals)\n",
    "    \n",
    "    val_losses.append(valid_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f} | F1: {val_f1}, weighted F1: {val_f1_w}, micro F1: {val_f1_mic}%')\n",
    "    print(classification_report(true_vals.detach().cpu().numpy(), predictions.detach().cpu().numpy()))\n",
    "    if valid_loss <= valid_loss_min:\n",
    "      print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "      valid_loss_min = valid_loss\n",
    "      torch.save(model.state_dict(), PATH)  \n",
    "plotLosses(train_losses,val_losses)\n",
    "\n",
    "test_loss , test_acc,predictions_tst,true_vals,IDs=test(model, test_iterator,PATH)\n",
    "val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions_tst.detach().cpu().numpy()\n",
    ", true_vals.detach().cpu().numpy()\n",
    ")\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} F1: {val_f1}, weighted F1: {val_f1_w}, micro F1: {val_f1_mic} % ')\n",
    "\n",
    "print(classification_report(true_vals.detach().cpu().numpy()\n",
    ", predictions_tst.detach().cpu().numpy()))\n",
    "\n",
    "#These are the list of the _id and needed to combine with true_vals to make the CSV for hasoc submission\n",
    "#print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_class = predict_class(model, \" I hate you\")\n",
    "#print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[int(round(pred_class))]} with label {int(round(pred_class))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-diloGPT",
   "language": "python",
   "name": "env-dilogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
