{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import spacy # use <!pip install spacy> and <!python -m spacy download en> if you dont have spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#select the path where you want to save model prameters\n",
    "\n",
    "PATH = '/home/sanala/Juputer try/HSD/model-parameters/bi-lstm-hasoc.pt'\n",
    "\n",
    "\n",
    "#Select which data you want to work with \n",
    "#data path\n",
    "DataPath= '/home/sanala/Juputer try/HSD'   #change it to your path\n",
    "#data\n",
    "train_data='has21_traindata.csv'           #<has20_traindata.csv> or <has21_traindata.csv> or <has19-20-21_conmined_train.csv>\n",
    "valid_data='has21_devdata.csv'             #<has21_devdata.csv> or <has21_devdata.csv> or <has19-20-21_conmined_valid.csv>\n",
    "test_data= 'has21_testwithlabels.csv'            #<has21_testdata.csv> or <has21_testdatawithlabels.csv> <has21_testdata.csv>\n",
    "\n",
    "\n",
    "    \n",
    "def hasoc_combined_data():\n",
    "    data1a = pd.read_csv('has19_traindata.csv')\n",
    "    data2b = pd.read_csv('has19_devdata.csv')\n",
    "    data1aa = pd.read_csv('has20_traindata.csv')\n",
    "    data2bb = pd.read_csv('has20_devdata.csv')\n",
    "    data1aaa = pd.read_csv('has21_traindata.csv')\n",
    "    data2bbb = pd.read_csv('has21_devdata.csv')\n",
    "    \n",
    "    train_data, valid_data = pd.concat([data1a, data1aa, data1aaa]), pd.concat([data2b, data2bb, data2bbb])\n",
    "    test_data='hasoc21_testwithlabels.csv'\n",
    "    #if datayear == '2020':\n",
    "            #print('Using Hasoc combined data for Hasoc 2020 test data... ')\n",
    "            #testdata = pd.read_csv(args.has20_testdata)\n",
    "    #else:\n",
    "            #print('Using Hasoc combined data for Hasoc 2021 test data... ')\n",
    "    train_data.to_csv('/home/sanala/Juputer try/HSD/has19-20-21_conmined_train.csv')\n",
    "    valid_data.to_csv('/home/sanala/Juputer try/HSD/has19-20-21_conmined_valid.csv')\n",
    "    \n",
    "\n",
    "#set to True if you want to work with hasoc_combined 19_20_21\n",
    "hasoc_combined=False\n",
    "\n",
    "if hasoc_combined:\n",
    "    hasoc_combined_data()\n",
    "    train_data='has19-20-21_conmined_train.csv'           #<has21_traindata.csv> or <has_combined_traindata.csv>\n",
    "    valid_data='has19-20-21_conmined_valid.csv'             #<has21_devdata.csv> or <has21_devdata.csv>\n",
    "    test_data= 'has21_testdatawithlabels.csv'\n",
    "    \n",
    "\n",
    "#pre-preocessing \n",
    "def text_clean(text):\n",
    "    text = re.sub(r'[a-zA-Z0-9-_.]+@[a-zA-Z0-9-_.]+', '', text)                  # remove emails                    \n",
    "    text = re.sub(r'((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.|$)){4}', '', text)# remove IP address\n",
    "    text = re.sub(r'http\\S+', '', text)                                          # remove URLs\n",
    "    text = re.sub(r'www\\S+ ', '', text)                                          # remove URLs\n",
    "    text = re.sub(r'[^\\w\\s#@/:%.,_-]', '', text, flags=re.UNICODE)               # remove emojis+\n",
    "    text = re.sub(r'[#,@,&,<,>,\\,/,-]', '', text)\n",
    "    text = text.replace('[','')\n",
    "    text = text.replace(']','')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.replace(' {2,}', ' ')                                            # remove 2 or more spaces\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d', '', text)                                              # remove numbers\n",
    "\n",
    "    return text\n",
    "\n",
    "# define model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        text = text.permute(1, 0)\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)\n",
    "    \n",
    "#define function to plot training  loss vs validation loss to check  overfitting     \n",
    "def plotLosses(train_losses,val_losses):\n",
    "    plt.plot(train_losses,label='Training Loss')  \n",
    "    plt.plot(val_losses,label='Validation Loss')  \n",
    "    plt.legend() \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "#function to return  scors   \n",
    "def f1_score_func(preds, labels):\n",
    "    return f1_score(labels, preds, average=None), f1_score(labels, preds, average=\"weighted\"), f1_score(labels, preds, average=\"micro\")\n",
    "\n",
    "#training function \n",
    "def train(model, train_iterator, optimizer, criterion):\n",
    "    print ('start training' )   \n",
    "    \n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = criterion(predictions, batch.task_1)\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc += acc.item()\n",
    "             \n",
    "    return train_epoch_loss / len(train_iterator), train_epoch_acc / len(train_iterator)\n",
    "\n",
    "#Evaluation  function\n",
    "def evaluation(model,valid_iterator):\n",
    "    print('Thin is the validation result')\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_acc = 0\n",
    "    predictions_tst = []\n",
    "    true_vals=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for batch in valid_iterator:\n",
    "\n",
    "          predictions = model(batch.text).squeeze(1)\n",
    "          for a in predictions:            # pick each element - no list comprehension\n",
    "            predictions_tst.append(torch.round(torch.sigmoid(a)))\n",
    "          for a in batch.task_1: \n",
    "            true_vals.append(a)\n",
    "\n",
    "          loss = criterion(predictions, batch.task_1)\n",
    "\n",
    "          rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "          correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "          acc = correct.sum()/len(correct)\n",
    "\n",
    "          valid_epoch_loss += loss.item()\n",
    "          valid_epoch_acc += acc.item()\n",
    "\n",
    "    predictions_tst = torch.stack(predictions_tst)\n",
    "    true_vals = torch.stack(true_vals)\n",
    "    #valid_loss = valid_epoch_loss / len(valid_iterator)\n",
    "    #valid_acc = valid_epoch_acc / len(valid_iterator) \n",
    "       \n",
    "    return valid_epoch_loss / len(valid_iterator), valid_epoch_acc / len(valid_iterator ),predictions_tst,true_vals    \n",
    "#test function\n",
    "\n",
    "def test(model, test_iterator,path):\n",
    "  print ('this the testing result' )   \n",
    "\n",
    "  epoch_loss = 0\n",
    "  epoch_acc = 0\n",
    "  model.load_state_dict(torch.load(path))\n",
    "\n",
    "  model.eval()\n",
    "  predictions_tst = []\n",
    "  true_vals=[]\n",
    "  IDs=[]\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "      for batch in test_iterator:\n",
    "\n",
    "          predictions = model(batch.text).squeeze(1)\n",
    "          for a in predictions:            # pick each element - no list comprehension\n",
    "            predictions_tst.append(torch.round(torch.sigmoid(a)))\n",
    "          for a in batch.task_1: \n",
    "            true_vals.append(a)\n",
    "          for a in batch._id: \n",
    "            IDs.append(a)#better if it was a dictionary (id:label)\n",
    "         \n",
    "          loss = criterion(predictions, batch.task_1)\n",
    "          rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "          correct = (rounded_preds == batch.task_1).float() \n",
    "        \n",
    "          acc = correct.sum()/len(correct)\n",
    "\n",
    "          epoch_loss += loss.item()\n",
    "          epoch_acc += acc.item()\n",
    "\n",
    "  predictions_tst = torch.stack(predictions_tst)\n",
    "  true_vals = torch.stack(true_vals)\n",
    " \n",
    "  test_loss = epoch_loss / len(test_iterator)\n",
    "  test_acc = epoch_acc / len(test_iterator)\n",
    "  return test_loss , test_acc,predictions_tst,true_vals,IDs\n",
    "\n",
    "#function to test user input\n",
    "def predict_class(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start pre-processin\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(s): \n",
    "    return [w.text.lower() for w in nlp(text_clean(s))]\n",
    "TEXT = torchtext.legacy.data.Field(tokenize = tokenizer)\n",
    "\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype = torch.float)\n",
    "ID = torchtext.legacy.data.RawField()\n",
    "datafields = [('_id', ID) ,('text', TEXT),('task_1', LABEL) ,('task_2', None)]\n",
    "\n",
    "#read data\n",
    "#change the path \n",
    "trn,vld, tst = torchtext.legacy.data.TabularDataset.splits(path =DataPath, \n",
    "                                                train = train_data,\n",
    "                                                validation=valid_data,\n",
    "                                                test = test_data,    \n",
    "                                                format = 'csv',\n",
    "                                                skip_header = True,\n",
    "                                                fields = datafields)\n",
    "#check data\n",
    "#print(f'Number of training examples: {len(trn)}')\n",
    "#print(f'Number of validation examples: {len(vld)}')\n",
    "#print(f'Number of testing examples: {len(tst)}')\n",
    "\n",
    "#vars(trn.examples[0\n",
    "#vars(tst.examples[50])\n",
    "\n",
    "TEXT.build_vocab(trn, max_size=25000,\n",
    "                 vectors=\"glove.6B.100d\",## #pretrained vectors are ['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d']\n",
    "                 unk_init=torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)\n",
    "#print(LABEL.vocab.stoi)\n",
    "train_iterator,valid_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "                                (trn,vld, tst),\n",
    "                                batch_size = 50,\n",
    "                                sort_key=lambda x: len(x.text),\n",
    "                                sort_within_batch=False,\n",
    "                                device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    " \n",
    "#print(pretrained_embeddings.shape)\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM) \n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model=model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "#print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 01 | Train Loss: 0.599 | Train Acc: 69.36% | Valid Loss: 0.543 | Valid Acc: 74.75 | F1: [0.81851852 0.57391304], weighted F1: 0.7327477675303762, micro F1: 0.7454545454545455%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.88      0.82       250\n",
      "         1.0       0.69      0.49      0.57       135\n",
      "\n",
      "    accuracy                           0.75       385\n",
      "   macro avg       0.73      0.69      0.70       385\n",
      "weighted avg       0.74      0.75      0.73       385\n",
      "\n",
      "Validation loss decreased (inf --> 0.543435).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 02 | Train Loss: 0.508 | Train Acc: 75.93% | Valid Loss: 0.504 | Valid Acc: 75.89 | F1: [0.83060109 0.57918552], weighted F1: 0.7424423856439285, micro F1: 0.7584415584415585%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83       250\n",
      "         1.0       0.74      0.47      0.58       135\n",
      "\n",
      "    accuracy                           0.76       385\n",
      "   macro avg       0.75      0.69      0.70       385\n",
      "weighted avg       0.76      0.76      0.74       385\n",
      "\n",
      "Validation loss decreased (0.543435 --> 0.504217).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 03 | Train Loss: 0.438 | Train Acc: 79.68% | Valid Loss: 0.492 | Valid Acc: 77.11 | F1: [0.84078712 0.57819905], weighted F1: 0.7487107844211338, micro F1: 0.7688311688311689%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.94      0.84       250\n",
      "         1.0       0.80      0.45      0.58       135\n",
      "\n",
      "    accuracy                           0.77       385\n",
      "   macro avg       0.78      0.70      0.71       385\n",
      "weighted avg       0.78      0.77      0.75       385\n",
      "\n",
      "Validation loss decreased (0.504217 --> 0.491656).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 04 | Train Loss: 0.382 | Train Acc: 83.36% | Valid Loss: 0.481 | Valid Acc: 77.50 | F1: [0.84153005 0.60633484], weighted F1: 0.7590590059249654, micro F1: 0.7740259740259741%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.92      0.84       250\n",
      "         1.0       0.78      0.50      0.61       135\n",
      "\n",
      "    accuracy                           0.77       385\n",
      "   macro avg       0.78      0.71      0.72       385\n",
      "weighted avg       0.77      0.77      0.76       385\n",
      "\n",
      "Validation loss decreased (0.491656 --> 0.481215).   Saving model ...\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 05 | Train Loss: 0.312 | Train Acc: 87.19% | Valid Loss: 0.487 | Valid Acc: 76.39 | F1: [0.83116883 0.60606061], weighted F1: 0.7522347782088042, micro F1: 0.7636363636363637%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.90      0.83       250\n",
      "         1.0       0.73      0.52      0.61       135\n",
      "\n",
      "    accuracy                           0.76       385\n",
      "   macro avg       0.75      0.71      0.72       385\n",
      "weighted avg       0.76      0.76      0.75       385\n",
      "\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 06 | Train Loss: 0.248 | Train Acc: 90.25% | Valid Loss: 0.490 | Valid Acc: 77.79 | F1: [0.83685221 0.65863454], weighted F1: 0.7743602973351141, micro F1: 0.7792207792207793%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.87      0.84       250\n",
      "         1.0       0.72      0.61      0.66       135\n",
      "\n",
      "    accuracy                           0.78       385\n",
      "   macro avg       0.76      0.74      0.75       385\n",
      "weighted avg       0.77      0.78      0.77       385\n",
      "\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 07 | Train Loss: 0.201 | Train Acc: 93.03% | Valid Loss: 0.504 | Valid Acc: 77.54 | F1: [0.83773585 0.64166667], weighted F1: 0.7689843175692231, micro F1: 0.7766233766233768%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.89      0.84       250\n",
      "         1.0       0.73      0.57      0.64       135\n",
      "\n",
      "    accuracy                           0.78       385\n",
      "   macro avg       0.76      0.73      0.74       385\n",
      "weighted avg       0.77      0.78      0.77       385\n",
      "\n",
      "start training\n",
      "Thin is the validation result\n",
      "| Epoch: 08 | Train Loss: 0.150 | Train Acc: 95.11% | Valid Loss: 0.587 | Valid Acc: 78.96 | F1: [0.85304659 0.61320755], weighted F1: 0.7689471886063487, micro F1: 0.787012987012987%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.95      0.85       250\n",
      "         1.0       0.84      0.48      0.61       135\n",
      "\n",
      "    accuracy                           0.79       385\n",
      "   macro avg       0.81      0.72      0.73       385\n",
      "weighted avg       0.80      0.79      0.77       385\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this the testing result\n",
      "Test Loss: 0.473 | Test Acc: 78.44 F1: [0.84335982 0.655     ], weighted F1: 0.77233890325822, micro F1: 0.784543325526932 % \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.93      0.84       798\n",
      "         1.0       0.83      0.54      0.66       483\n",
      "\n",
      "    accuracy                           0.78      1281\n",
      "   macro avg       0.80      0.74      0.75      1281\n",
      "weighted avg       0.79      0.78      0.77      1281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 8\n",
    "valid_loss_min = np.Inf \n",
    "val_losses=[]\n",
    "train_losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "     \n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc,predictions,true_vals = evaluation(model, valid_iterator)\n",
    "\n",
    "    val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions.detach().cpu().numpy(), true_vals.detach().cpu().numpy())\n",
    "    #val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions, true_vals)\n",
    "    \n",
    "    val_losses.append(valid_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Valid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f} | F1: {val_f1}, weighted F1: {val_f1_w}, micro F1: {val_f1_mic}%')\n",
    "    print(classification_report(true_vals.detach().cpu().numpy()\n",
    ", predictions.detach().cpu().numpy()))\n",
    "    if valid_loss <= valid_loss_min:\n",
    "      print('Validation loss decreased ({:.6f} --> {:.6f}).   Saving model ...'.format(valid_loss_min,valid_loss))\n",
    "      valid_loss_min = valid_loss\n",
    "      torch.save(model.state_dict(), PATH)  \n",
    "plotLosses(train_losses,val_losses)\n",
    "\n",
    "test_loss , test_acc,predictions_tst,true_vals,IDs=test(model, test_iterator,PATH)\n",
    "val_f1, val_f1_w, val_f1_mic = f1_score_func(predictions_tst.detach().cpu().numpy()\n",
    ", true_vals.detach().cpu().numpy()\n",
    ")\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f} F1: {val_f1}, weighted F1: {val_f1_w}, micro F1: {val_f1_mic} % ')\n",
    "\n",
    "print(classification_report(true_vals.detach().cpu().numpy()\n",
    ", predictions_tst.detach().cpu().numpy()))\n",
    "#These are the list of the _id and needed to combine with true_vals to make the CSV for hasoc submission\n",
    "#print(IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-diloGPT",
   "language": "python",
   "name": "env-dilogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
